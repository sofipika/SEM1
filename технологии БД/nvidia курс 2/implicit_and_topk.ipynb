{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><a href=\"https://www.nvidia.com/en-us/deep-learning-ai/education/\"><img src=\"../../images/DLI_Header.png\"></a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implicit Feedback and Top K Accuracy\n",
    "\n",
    "In the lab so far, we've been trying to predict the user's rating of an item. This type of feedback is **explicit**, meaning the user was consciously giving us feedback. Other examples might include a \"thumbs up\" or \"like\". This is valuable insight, but not all users want to take the time to give thoughtful feedback, so instead, many companies use **implicit** feedback instead, where a user's behavior might be a better metric for their satisfaction.\n",
    "\n",
    "## Objective\n",
    "* Understand how to extract Implicit Feedback\n",
    "* Learn how to use the Top K Accuracy metric.\n",
    "\n",
    "## Implicit Feedback\n",
    "\n",
    "Let's take a look at YouTube. YouTube trains its recommendation model on [watch time](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf). The user isn't consciously giving feedback to YouTube when watching a video, but we might make an assumption that if a user watches a long video, they probably enjoy it, and the longer users are on the site, the more ads they can show.\n",
    "\n",
    "Another example is Amazon. In 2003, its algorithm was based on Item-to-Item Collaborative Filtering. Remember our User-Item interaction matrix from Lab 1? Instead of comparing users with items, Amazon used the same item indices for both rows and columns. Then, it would keep track of how often one item was purchased with another. Amazon has since moved on to researching and applying a wide variety of systems, a history of which can be found [here](https://www.amazon.science/the-history-of-amazons-recommendation-algorithm).\n",
    "\n",
    "[Facebook](https://engineering.fb.com/core-data/recommending-items-to-more-than-a-billion-people/) similarly uses a form of implicit feedback based on a confidence score of a user's explicit feedback.\n",
    "\n",
    "For more information on implicit feedback, check out [this paper](https://terpconnect.umd.edu/~oard/pdf/aaai98.pdf).\n",
    "\n",
    "|Types of Explicit Feedback|Types of Implicit Feedback|\n",
    "|--------|--------|\n",
    "| 1 - 5 stars | Watch time |\n",
    "| Like / Dislike | Click-through rate|\n",
    "| + 1 Button | Link sharing |\n",
    "| Written review | Amount bought |\n",
    "\n",
    "\n",
    "## Deriving Implicit Feedback\n",
    "\n",
    "Finding implicit feedback can sometimes take a bit of creativity. Let's load the Amazon Dataset we've been using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, concatenate, Dense\n",
    "\n",
    "ratings = pd.read_csv(\"../../data/task_2.csv\")\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using the rating directly, let us instead consider simply if an item was purchased. To keep things simple, let us see if we can use the user embedding to predict what item they purchased for their review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings[['item_index', 'user_embed_0', 'user_embed_1', 'valid']]\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are not going to use our `'overall'` column as the label, what should we choose? Since we're trying to predict what item the user is making a rating for, we'll use `item_index` and assign each item a probability.\n",
    "\n",
    "This unfortunately means we can't use any user x item interaction features or properties of the item as inputs, but there are other advantages to this structure. Since we have an output for each item, we only need to run the model once to get the top recommended items for a user. No need to compare it to every item since that's built into the model!\n",
    "\n",
    "To do this, we'll need to keep track of the number of items. We've already factorized the index, so we just need to find the max number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ITEMS = ratings['item_index'].max() + 1\n",
    "NUM_ITEMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, let us build a tf.data pipeline. Since we have an output for each item, our loss will be very large at first. To prevent Not a Number (NaN) errors, we'll train based on batches instead of epochs. If we leave the [repeat](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#repeat) method of a tf.data dataset as `None`, the dataset will continue indefinitely.\n",
    "\n",
    "We'll define how many batches to train on by specifying a number of steps when we fit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ds_from_df(df_tmp, cols, label, batch_size=1028, repeats=None):\n",
    "    dataset = (\n",
    "        tf.data.Dataset.from_tensor_slices(\n",
    "            (df_tmp[cols].to_dict(\"list\"), df_tmp[label].values)\n",
    "        )\n",
    "        .shuffle(len(df_tmp))\n",
    "        .repeat(repeats)\n",
    "        .batch(batch_size)\n",
    "        .prefetch(1)\n",
    "    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's build our input tensors, just like the previous lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_user_embed_0 = Input(name=\"user_embed_0\", shape=(1), dtype=\"float32\")\n",
    "input_user_embed_1 = Input(name=\"user_embed_1\", shape=(1), dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = {\n",
    "    \"user_embed_0\": input_user_embed_0,\n",
    "    \"user_embed_1\": input_user_embed_1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "\n",
    "We'll build our neural network mostly as usual, but the difference from previous labs is the last layer. Now, we have an output neuron for each of our different items. We're using a [Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) layer this time, but since we're predicting the  chance that a user will review an item, [Softmax](https://www.tensorflow.org/api_docs/python/tf/nn/softmax) would also work. Our dense layer will have a linear activation where the outputs are called a `logit`. For our use case, we are looking for the maximum prediction, so calculating a probability here would be extra computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense Neural Network\n",
    "inputs = concatenate([input_user_embed_0, input_user_embed_1], axis=1)\n",
    "x = Dense(10000, activation=\"relu\", name=\"hidden_1\")(inputs)\n",
    "x = Dense(5000, activation=\"relu\", name=\"hidden_2\")(x)\n",
    "output_tensor = Dense(NUM_ITEMS, activation=None, name=\"logits\")(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visually inspect the model to verify it's been set up correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(input_tensor, output_tensor)\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, rankdir='LR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're using the item index as our label, we will use [SparseCategoricalCrossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy) for our loss. This way, TensorFlow does not have to search to find the index matching our label. This is very useful in situations like our Amazon dataset where we have thousands of outputs! We will set `from_logits` as `True` so our loss function can turn our predictions into a probability to compare against the label. \n",
    "\n",
    "To keep consistency, we'll use [SparseCategoricalAccuracy](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/SparseCategoricalAccuracy). This accuracy metric expects data to be in the same format as what is used for `SparseCategoricalCrossentry` (meaning the label is an index). A debugging tip: if the model accuracy is always `0`, one thing to check is to make sure the correct accuracy metric is being used for the type of data the model is learning on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics = [tf.keras.metrics.SparseCategoricalAccuracy(name=\"acc\")]\n",
    "model.compile(optimizer=\"adam\", loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's prepare our tf.data dataset. We've specified the number of repeats for our validation data, but not for training. Since not specifying the number of repeats means that the dataset will loop forever, the validation step in our training will run forever. We'll put a `1` here to make sure the validation is gone through at least once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cols = ['user_embed_0', 'user_embed_1']\n",
    "train_ds = ratings[~ratings[\"valid\"]]\n",
    "train_ds = get_ds_from_df(train_ds, data_cols, 'item_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ds = ratings[ratings[\"valid\"]]\n",
    "valid_ds = get_ds_from_df(valid_ds, data_cols, 'item_index', repeats=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, moment of truth! Let's see how well our model trains. For [model.fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit) we've defined both `epochs` and `steps_per_epoch`.\n",
    "\n",
    "`steps_per_epoch` is how many batches we want to train on per `epoch`. This isn't an epoch in the traditional sense of machine learning that is one full pass of the dataset. This epoch is a collection of batches that are ingested by our model one step at a time, just like how a set is a number of repititions in weight training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds, validation_data=valid_ds, epochs=5, steps_per_epoch=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top K Accuracy\n",
    "\n",
    "Hmm, it is looking like our accuracy is a bit low, less than 1%. This is due to a number of reasons:\n",
    "* We are not using any contextual information other than the user embeddings.\n",
    "* Users rate multiple items, not just one.\n",
    "* Think of how often a user chooses to interact with an advertisement. Accuracy for these types of recommendation models are historically low. This is not a bad thing! If users interact with an advertisement 10% of the time, that can still lead to good business.\n",
    "\n",
    "To account for this, we'll use another metric called [Top K Accuracy](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/TopKCategoricalAccuracy?hl=fr). What this means is we'll look at the top K recommended items and see if any of them match the label. If we do, we'll call that a hit, otherwise, it's a miss.\n",
    "\n",
    "In order to use this metric, we'll need to compare our label against each output, meaning, [SparseCategoricalCrossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy) does not have the information we need. Instead, we'll use [CategoricalCrossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy). This loss expects our label to be a one-hot encoding.\n",
    "\n",
    "It would take a lot of space in our DataFrame to do this one-hot encoding (63001 columns!), so instead, we'll do it in batches. tf.data has a [map](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map) function that allows us to map a function to our features and labels. We'll use this with [tf.one_hot](https://www.tensorflow.org/api_docs/python/tf/one_hot) to get the format we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(features, label):\n",
    "    label = tf.one_hot(label, NUM_ITEMS)\n",
    "    return features, label\n",
    "\n",
    "def get_ds_from_df(df_tmp, cols, label, batch_size=1028, repeats=None):\n",
    "    dataset = (\n",
    "        tf.data.Dataset.from_tensor_slices(\n",
    "            (df_tmp[cols].to_dict(\"list\"), df_tmp[label].values)\n",
    "        )\n",
    "        .shuffle(len(df_tmp))\n",
    "        .repeat(repeats)\n",
    "        .batch(batch_size)\n",
    "        .map(one_hot)\n",
    "        .prefetch(1)\n",
    "    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's recompile our model with our new metrics and loss. This time, we'll use [CategoricalAccuracy](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/CategoricalAccuracy) to reflect our new data structure.\n",
    "\n",
    "We'll also set our `K` to `200`, meaning if the label is in the top 200 recommendations, that's a success. The appropriate number for K is going to depend on how these recommendations are served to users. For instance, if it's a travel website that shows the top 10 recommended travel destinations, then `K` should be 10 to reflect this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.Model(input_tensor, output_tensor)\n",
    "top_k = tf.keras.metrics.TopKCategoricalAccuracy(200, name=\"topk\")\n",
    "accuracy = tf.keras.metrics.CategoricalAccuracy(name=\"acc\")\n",
    "metrics = [top_k, metrics]\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=\"adam\", loss=loss, metrics=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll grab our new one-hot encoded dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ratings[~ratings[\"valid\"]]\n",
    "train_ds = get_ds_from_df(train_ds, data_cols, 'item_index')\n",
    "valid_ds = ratings[ratings[\"valid\"]]\n",
    "valid_ds = get_ds_from_df(valid_ds, data_cols, 'item_index', repeats=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's run our new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds, validation_data=valid_ds, epochs=5, steps_per_epoch=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over 10% top K accuracy. Considering we added no other contextual information, this is not bad! Trying to decide whether Wide and Deep or this is better? Since we're not running the model for every item, consider using structure when speed is a priority. If model size is an issue with so many outputs, consider trimming the item pool to the more popular items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><a href=\"https://www.nvidia.com/en-us/deep-learning-ai/education/\"><img src=\"../../images/DLI_Header.png\"></a></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
